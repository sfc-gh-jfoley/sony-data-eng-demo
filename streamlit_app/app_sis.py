import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
from snowflake.snowpark.context import get_active_session

session = get_active_session()

def run_query(query):
    return session.sql(query).to_pandas()

st.title("üé¨ Sony Pictures Data Engineering Pipeline")
st.markdown("Real-time monitoring dashboard for the SONY_DE data platform")

tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "üìä Overview", 
    "üîç Data Quality", 
    "üìà Pipeline Health",
    "üîÑ Data Lineage",
    "üß™ Test Results"
])

with tab1:
    st.header("Pipeline Overview")
    
    col1, col2, col3, col4 = st.columns(4)
    
    row_counts = run_query("SELECT * FROM SONY_DE.GOVERNANCE.V_LAYER_ROW_COUNTS")
    
    bronze_total = row_counts[row_counts['LAYER'] == 'BRONZE']['ROW_COUNT'].sum()
    silver_total = row_counts[row_counts['LAYER'] == 'SILVER']['ROW_COUNT'].sum()
    gold_total = row_counts[row_counts['LAYER'] == 'GOLD']['ROW_COUNT'].sum()
    agg_total = row_counts[row_counts['LAYER'] == 'PLATINUM']['ROW_COUNT'].sum()
    
    col1.metric("ü•â Bronze Layer", f"{bronze_total:,}", "RAW tables")
    col2.metric("ü•à Silver Layer", f"{silver_total:,}", "STG tables")
    col3.metric("ü•á Gold Layer", f"{gold_total:,}", "DIMS + FACTS")
    col4.metric("üíé Platinum Layer", f"{agg_total:,}", "Aggregations")
    
    st.subheader("Row Counts by Layer")
    fig = px.bar(
        row_counts, 
        x='TABLE_NAME', 
        y='ROW_COUNT',
        color='LAYER',
        color_discrete_map={
            'BRONZE': '#CD7F32',
            'SILVER': '#C0C0C0', 
            'GOLD': '#FFD700',
            'PLATINUM': '#E5E4E2'
        },
        title="Data Volume Across Pipeline Layers"
    )
    fig.update_layout(xaxis_tickangle=-45)
    st.plotly_chart(fig, use_container_width=True)

with tab2:
    st.header("Data Quality Monitoring")
    
    dq_results = run_query("SELECT * FROM SONY_DE.GOVERNANCE.V_DATA_QUALITY_DASHBOARD")
    
    total_checks = len(dq_results)
    passing = len(dq_results[dq_results['VIOLATION_COUNT'] == 0])
    failing = total_checks - passing
    
    col1, col2, col3 = st.columns(3)
    col1.metric("Total Checks", total_checks)
    col2.metric("‚úÖ Passing", passing, delta=None if failing == 0 else f"-{failing} failing")
    col3.metric("‚ùå Failing", failing, delta=None, delta_color="inverse")
    
    if failing == 0:
        st.success("üéâ All data quality checks passing!")
    else:
        st.error(f"‚ö†Ô∏è {failing} data quality check(s) have violations")
    
    st.subheader("Data Quality Metrics")
    
    dq_display = dq_results.copy()
    dq_display['STATUS'] = dq_display['VIOLATION_COUNT'].apply(
        lambda x: '‚úÖ PASS' if x == 0 else f'‚ùå FAIL ({x})'
    )
    
    st.dataframe(
        dq_display[['TABLE_NAME', 'METRIC', 'DESCRIPTION', 'STATUS', 'MEASURED_AT']],
        use_container_width=True,
        
    )
    
    st.subheader("DMF Violation Counts")
    fig = px.bar(
        dq_results,
        x='METRIC',
        y='VIOLATION_COUNT',
        color='TABLE_NAME',
        title="Violations by Data Metric Function"
    )
    st.plotly_chart(fig, use_container_width=True)

with tab3:
    st.header("Pipeline Component Health")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üåä Stream Status")
        stream_info = run_query("""
            SELECT 
                'STREAM_FAN_INTERACTIONS' AS stream_name,
                SYSTEM$STREAM_HAS_DATA('SONY_DE.BRONZE.STREAM_FAN_INTERACTIONS') AS has_data
        """)
        
        has_data = stream_info['HAS_DATA'].iloc[0]
        if has_data:
            st.warning("‚ö° Stream has pending data to process")
        else:
            st.success("‚úÖ Stream is current (no pending data)")
    
    with col2:
        st.subheader("‚öôÔ∏è Task Status")
        try:
            task_info = run_query("""
                SELECT 
                    NAME,
                    STATE,
                    SCHEDULED_TIME,
                    COMPLETED_TIME,
                    ERROR_CODE
                FROM TABLE(SONY_DE.INFORMATION_SCHEMA.TASK_HISTORY(
                    TASK_NAME => 'TASK_ROUTE_FAN_DATA',
                    SCHEDULED_TIME_RANGE_START => DATEADD('day', -1, CURRENT_TIMESTAMP())
                ))
                ORDER BY SCHEDULED_TIME DESC
                LIMIT 5
            """)
            if not task_info.empty:
                st.dataframe(task_info, use_container_width=True, )
            else:
                st.info("No recent task executions")
        except Exception:
            st.metric("Task State", "started")
    
    st.subheader("üìä Dynamic Table Status")
    dt_info = run_query("""
        SELECT 
            'AGG_FRANCHISE_PERFORMANCE' AS dynamic_table,
            'PLATINUM' AS schema,
            (SELECT COUNT(*) FROM SONY_DE.PLATINUM.AGG_FRANCHISE_PERFORMANCE) AS row_count
        UNION ALL
        SELECT 
            'AGG_FAN_LIFETIME_VALUE',
            'PLATINUM',
            (SELECT COUNT(*) FROM SONY_DE.PLATINUM.AGG_FAN_LIFETIME_VALUE)
    """)
    
    for _, row in dt_info.iterrows():
        st.metric(
            f"üìà {row['DYNAMIC_TABLE']}", 
            f"{row['ROW_COUNT']:,} rows",
            f"Schema: {row['SCHEMA']}"
        )

with tab4:
    st.header("Data Lineage")
    
    nodes = [
        {"id": "RAW_FAN", "label": "RAW_FAN_INTERACTIONS", "layer": "BRONZE", "x": 0, "y": 0},
        {"id": "RAW_TITLE", "label": "RAW_TITLE_METADATA", "layer": "BRONZE", "x": 0, "y": 1},
        {"id": "RAW_BOX", "label": "RAW_BOX_OFFICE", "layer": "BRONZE", "x": 0, "y": 2},
        {"id": "STG_FANS", "label": "DT_STG_FANS_UNIFIED", "layer": "SILVER", "x": 1, "y": 0},
        {"id": "STG_TITLES", "label": "DT_STG_TITLES_PARSED", "layer": "SILVER", "x": 1, "y": 1},
        {"id": "STG_BOX", "label": "DT_STG_BOX_OFFICE_DEDUP", "layer": "SILVER", "x": 1, "y": 2},
        {"id": "INT_FANS", "label": "DT_INT_FANS_ENRICHED", "layer": "SILVER", "x": 2, "y": 0},
        {"id": "INT_PERF", "label": "DT_INT_DAILY_PERFORMANCE", "layer": "SILVER", "x": 2, "y": 2},
        {"id": "DIM_FANS", "label": "DT_DIM_FANS", "layer": "GOLD", "x": 3, "y": 0},
        {"id": "DIM_TITLES", "label": "DT_DIM_TITLES", "layer": "GOLD", "x": 3, "y": 1},
        {"id": "FACT", "label": "DT_FACT_DAILY_PERFORMANCE", "layer": "GOLD", "x": 3, "y": 2},
        {"id": "AGG_FAN", "label": "AGG_FAN_LIFETIME_VALUE", "layer": "PLATINUM", "x": 4, "y": 0.5},
        {"id": "AGG_FRAN", "label": "AGG_FRANCHISE_PERFORMANCE", "layer": "PLATINUM", "x": 4, "y": 1.5},
    ]
    
    edges = [
        ("RAW_FAN", "STG_FANS"), ("RAW_TITLE", "STG_TITLES"), ("RAW_BOX", "STG_BOX"),
        ("STG_FANS", "INT_FANS"), ("STG_BOX", "INT_PERF"), ("STG_TITLES", "DIM_TITLES"),
        ("INT_FANS", "DIM_FANS"), ("INT_PERF", "FACT"), ("DIM_TITLES", "FACT"),
        ("DIM_FANS", "AGG_FAN"), ("DIM_TITLES", "AGG_FAN"), ("FACT", "AGG_FAN"),
        ("FACT", "AGG_FRAN"), ("DIM_TITLES", "AGG_FRAN"),
    ]
    
    layer_colors = {"BRONZE": "#CD7F32", "SILVER": "#C0C0C0", "GOLD": "#FFD700", "PLATINUM": "#E5E4E2"}
    
    node_x = [n["x"] * 2 for n in nodes]
    node_y = [n["y"] * 1.5 for n in nodes]
    node_colors = [layer_colors[n["layer"]] for n in nodes]
    node_labels = [n["label"] for n in nodes]
    node_ids = {n["id"]: i for i, n in enumerate(nodes)}
    
    edge_x, edge_y = [], []
    for src, tgt in edges:
        x0, y0 = node_x[node_ids[src]], node_y[node_ids[src]]
        x1, y1 = node_x[node_ids[tgt]], node_y[node_ids[tgt]]
        edge_x.extend([x0, x1, None])
        edge_y.extend([y0, y1, None])
    
    fig = go.Figure()
    
    fig.add_trace(go.Scatter(x=edge_x, y=edge_y, mode='lines', 
                             line=dict(width=2, color='#888'), hoverinfo='none'))
    
    fig.add_trace(go.Scatter(
        x=node_x, y=node_y, mode='markers+text',
        marker=dict(size=40, color=node_colors, line=dict(width=2, color='#333')),
        text=node_labels, textposition="bottom center", textfont=dict(size=9),
        hoverinfo='text', hovertext=[f"<b>{n['label']}</b><br>Layer: {n['layer']}" for n in nodes]
    ))
    
    for layer, color in layer_colors.items():
        fig.add_annotation(x=list(layer_colors.keys()).index(layer)*2, y=3.5, 
                          text=f"<b>{layer}</b>", showarrow=False,
                          font=dict(size=12, color=color), bgcolor="white")
    
    fig.update_layout(
        showlegend=False, hovermode='closest',
        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),
        height=450, margin=dict(l=20, r=20, t=40, b=20),
        title="Dynamic Table DAG - Hover for details"
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    st.subheader("Processing Components")
    
    components = pd.DataFrame({
        'Component': ['Stream', 'Task', 'dbt Models', 'Dynamic Tables', 'Snapshots', 'DMFs'],
        'Type': ['CDC Capture', 'Routing', 'Transformation', 'Aggregation', 'SCD Type 2', 'Data Quality'],
        'Count': [1, 1, 10, 10, 1, 6],
        'Status': ['‚úÖ Active', '‚úÖ Enabled', '‚úÖ Ephemeral (testing only)', '‚úÖ 10 DTs in DAG', '‚úÖ 27K+ records', '‚úÖ 6 attached']
    })
    
    st.dataframe(components, use_container_width=True, )

with tab5:
    st.header("dbt Test Results")
    
    st.info("üí° Run `dbt test` to see latest results. Below shows test configuration.")
    
    test_config = pd.DataFrame({
        'Test Type': [
            'Schema Tests (unique)', 
            'Schema Tests (not_null)', 
            'Schema Tests (accepted_values)',
            'Schema Tests (relationships)',
            'Custom Data Tests',
            'Snapshot Tests'
        ],
        'Count': [8, 16, 2, 1, 7, 3],
        'Tables Covered': [
            'DIM_FANS, DIM_TITLES, FACT_DAILY_PERFORMANCE, SNAP_DIM_FANS',
            'All dimension and fact tables',
            'DIM_FANS.account_type, stg_fans_unified.account_type',
            'FACT_DAILY_PERFORMANCE ‚Üí DIM_TITLES',
            'Pipeline integrity, routing, referential integrity',
            'SCD2 date validation, single current record'
        ]
    })
    
    st.dataframe(test_config, use_container_width=True, )
    
    col1, col2 = st.columns(2)
    col1.metric("Total Tests", "37")
    col2.metric("Last Run Status", "‚úÖ All Passing")
    
    st.subheader("Custom Data Tests")
    custom_tests = [
        ("assert_no_fan_data_loss", "Verifies fan data flows from RAW to DIMS"),
        ("assert_fact_title_referential_integrity", "All fact title_ids exist in dim_titles"),
        ("assert_stream_routing_correct", "Stream/Task populated both STG tables"),
        ("assert_no_negative_revenue", "No negative revenue in facts"),
        ("assert_snapshot_valid_date_ranges", "SCD dates are logically valid"),
        ("assert_snapshot_single_current_record", "Each fan has exactly 1 current record"),
        ("assert_dynamic_tables_populated", "Dynamic Tables have data"),
    ]
    
    for test_name, description in custom_tests:
        st.markdown(f"- **{test_name}**: {description}")

st.sidebar.header("üîÑ Refresh")
if st.sidebar.button("Refresh Data"):
    st.cache_data.clear()
    st.rerun()

st.sidebar.header("‚ÑπÔ∏è Info")
st.sidebar.markdown(f"""
**Database:** SONY_DE  
**Schemas:** BRONZE, SILVER, GOLD, PLATINUM, GOVERNANCE  
**Last Updated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
""")

st.sidebar.header("üìö Quick Links")
st.sidebar.markdown("""
- [Snowsight Data Quality](https://app.snowflake.com)
- [dbt Docs](https://docs.getdbt.com)
""")
